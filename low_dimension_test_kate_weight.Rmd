---
title: "Untitled"
output: html_document
date: "2025-05-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(jewel)
library(tidyverse)
library(JGL)
library(pROC)
library(pheatmap)
library(MASS)

library(spikeyglass)

#devtools::install_github("mljaniczek/spikeyglass")

# read in reference weights
realDataHist = read.csv("mxDist.csv")
source("00_helper_functions.R")

```

For all data, n = 1000 per arm, p = 500, k = 2 groups. 


Data generation 1: using a function from the `jewel` package

```{r}

set.seed(1219)
K <- 2 # number of groups
p <- 50 # number of vertices
n <- 100 # number of samples per group

# number of subnetworks
L <- 4
p_sub <- p/L  # features per subnetwork

dens1 <- 0.5
m <- 2
power <- 1
perc <- 0.1

# gsub <- vector(mode = "list", length = L)
# 
# for (l in 1:L) {
#   g <- as.matrix(as_adjacency_matrix(
#     sample_pa(p_sub, power = power, m = m, 
#               directed = FALSE)
#   ))
#   gsub[[l]] <- g
# }
# 
# g1 <- matrix(0, nrow = p, ncol = p)
# for (l in 1:L){
#   g1[((l -1)*p_sub+1):(l*p_sub),
#      ((l-1)*p_sub+1):(l*p_sub)] <- gsub[[l]]
# }

g1 = sample_gnp(p, dens1)

g1 = sample_islands(4, 50, 5/10, 1)

g1 = sample_pa(n=p, power=1, m=5, directed=F)


  # G2
# g1_graph <- graph_from_adjacency_matrix(g1)
# plot(g1_graph, vertex.label = NA, edge)

g2 = rewire(g1, keeping_degseq(niter = gsize(g1)*perc))
  
#G_diff_graph1 <- igraph::union(igraph::difference(g1_graph, g2_graph), 
 #                               igraph::difference(g2_graph, g1_graph))

#gsize(G_diff_graph1)

  
g1_unif <- g1_emp <- g1
g2_unif <- g2_emp <- g2
  
# assign edge weights
weights = sample(realDataHist$mids, replace=T,size=length(E(g1)), prob=realDataHist$density)  
weights1 = weights
weights2 = weights

# use this if you want to randomly make some of the weights 0 in each
#new_weight_index1 <- sample(c(TRUE, FALSE), replace = T, size = length(weights1), prob = c(.05, .95)) 
#new_weight_index2 <- sample(c(TRUE, FALSE), replace = T, size = length(weights1), prob = c(.05, .95)) 
#weights1[new_weight_index1] <- 0
#weights2[new_weight_index2] <- 0
  
E(g1_emp)$weights <- weights1
E(g2_emp)$weights <- weights2
  
size <- length(E(g1))
a <- 0.01
b <-  0.6
samp_right <- runif(ceiling(size / 2), min = a, max = b)
samp_left <- runif(ceiling(size / 2), min = -b, max = -a)
weights_unif <- sample(c(samp_left, samp_right), size)
weights_unif1 <- weights_unif2 <- weights_unif
#weights_unif1[new_weight_index1] <- 0
#weights_unif2[new_weight_index2] <- 0



E(g1_unif)$weights <- weights_unif1
E(g2_unif)$weights <- weights_unif2



precMat1_emp = boost(-1*as_adjacency_matrix(g1_emp, attr = c("weights"), type="both") + diag(length(g1_emp)))
precMat2_emp = boost(-1*as_adjacency_matrix(g2_emp, attr = c("weights"), type="both") + diag(length(g2_emp)))
precMat1_unif = boost(-1*as_adjacency_matrix(g1_unif, attr = c("weights"), type="both") + diag(length(g1_unif)))
precMat2_unif = boost(-1*as_adjacency_matrix(g2_unif, attr = c("weights"), type="both") + diag(length(g2_unif)))

sigma1_emp <- solve(precMat1_emp)
sigma2_emp <- solve(precMat2_emp)

g1_emp_graph <- graph_from_adjacency_matrix(-cov2cor(as.matrix(precMat1_emp)),
                                            weighted = T,
                                            mode = "undirected",
                                            diag = F)

plot(g1_emp_graph,
     vertex.label = NA,
     edge.width = ifelse(abs(E(g1_emp_graph)$weight)>0, 1.5, 0),
     vertex.size = (degree(g1_emp_graph)+2))

library(ggcorrplot)
ggcorrplot(sigma2_emp)



dat1_emp = scale(mvrnorm(n = 1000, mu = rep(0,nrow(precMat1_emp)), Sigma = solve(precMat1_emp)))
dat2_emp = scale(mvrnorm(n = 1000, mu = rep(0,nrow(precMat2_emp)), Sigma = solve(precMat2_emp)))
dat1_unif = scale(mvrnorm(n = 1000, mu = rep(0,nrow(precMat1_unif)), Sigma = solve(precMat1_unif)))
dat2_unif = scale(mvrnorm(n = 1000, mu = rep(0,nrow(precMat2_unif)), Sigma = solve(precMat2_unif)))

pheatmap(scale(dat1_unif))
pheatmap(scale(dat1_emp))
ggcorrplot(as.matrix(precMat1_emp))
ggcorrplot(as.matrix(precMat2_emp))
ggcorrplot(as.matrix(precMat1_unif))
ggcorrplot(as.matrix(precMat2_unif))

```


# FGL 

Tune parameters, then run with tuned parameters. 

```{r}
# now tuning lambda

interval_l = 10
lambda.eff <- seq(0.01, 0.4, len = interval_l)
aic_vec1 <- matrix(NA, length(lambda.eff), 1) #for lambda1
aic_vec2 <- matrix(NA, length(lambda.eff), 1) #for lambda2


X = list(dat1_emp, dat2_emp)
#search length of lambda1, keeping lambda2 constant and small
start.time = Sys.time()
for(i in 1:length(lambda.eff)){
  fit00 <- JGL(Y=X,penalty="fused",lambda1=lambda.eff[i],lambda2=lambda.eff[1], return.whole.theta=TRUE)
  aic_vec1[i,1] <- vBIC(X, fit00, thr=0.0001)
}

# identify which had min aic
i_idx <- which(aic_vec1 == min(aic_vec1), arr.ind = TRUE)[1,1]
#assign tuned lambda1 based on your search
lam_1 <- lambda.eff[i_idx]

#now search for lambda2, using value of lambda1 learned above
for(j in 1:length(lambda.eff)){
  fit00 <- JGL(Y=X,penalty="group",lambda1=lambda.eff[i_idx],lambda2=lambda.eff[j], return.whole.theta=TRUE)
  aic_vec2[j,1] <- vBIC(X, fit00, thr=0.0001)
}

# identify which lambda2 had min aic
j_idx <- which(aic_vec2 == min(aic_vec2), arr.ind = TRUE)[1,1]
#assign tuned lambda1 based on your search
lam_2 <- lambda.eff[j_idx]

end.time = Sys.time()

end.time-start.time

# 6.33 minutes for 500 features, 1000 per arm
# 48 seconds for 200 features, 1000 per arm

res_fgl <- JGL(Y=X,
                         penalty="fused",
                         lambda1= lam_1,
                         lambda2= lam_2,
                         return.whole.theta=TRUE)

#save(res_fgl, file = "fgl_res_n1000p200.rdata")

# get 5% percentile of absolute value of empirical dist
thresh <- quantile(abs(weights), .025)

curr_res1 <-  (abs(res_fgl$theta[[1]]) > thresh)*1

diag(curr_res1) = 0


curr_perf1 <- evaluatePerformance(g1, curr_res1)

curr_res2 <-  (abs(res_fgl$theta[[2]]) > thresh)*1

diag(curr_res2) = 0


curr_perf2 <- evaluatePerformance(g2, curr_res2)


res_df <- data.frame(
  tpr1 = curr_perf1[[1]]/(curr_perf1[[1]] + curr_perf1[[4]]),
  fpr1 = curr_perf1[[3]]/(curr_perf1[[3]] + curr_perf1[[2]]),
  auc = auc(roc(as.matrix(as_adjacency_matrix(g1)) ~ curr_res1))
  
)

res_df

emp_res_df <- res_df

emp_res_df
```


# SSJGL 

```{r}
set.seed(1219)

penalty <- "fused"
lam1 <- 1
lam2 <- 1
v1 <- 1
lam.eff <- lam1 + c(1:10) * 5
v0s <- lam1/lam.eff

start.time = Sys.time()
ssjgl_res <- ssjgl(Y=X,penalty=penalty,lambda0=1, lambda1=lam1,
                   lambda2=lam2, v1 = v1, v0s = v0s, a=1, b=p, doubly=TRUE, normalize=FALSE)
end.time = Sys.time()
end.time-start.time

#save(ssjgl_res, file = "ssjgl_res_n1000p200_island_unif.rdata")

#load("ssjgl_res_n1000p200.rdata")

# extract all estimated covariance matrices from result
ssjgl_covar_matrices <- ssjgl_res$thetalist[[3]]#[[length(v0s)]]
ss_res1 <- (abs(ssjgl_covar_matrices[[1]])>thresh)*1
diag(ss_res1) = 0
ss_perf1 <- evaluatePerformance(g1, ss_res1)

ss_res_df <- data.frame(
  tpr = ss_perf1[[1]]/(ss_perf1[[1]] + ss_perf1[[4]]),
  fpr = ss_perf1[[3]]/(ss_perf1[[3]] + ss_perf1[[2]]),
  auc = auc(roc(as.matrix(as_adjacency_matrix(g1))~ss_res1))
  
)
# 16 minutes

ss_res_df
emp_res_df

ss_res_df_unif <- ss_res_df


plot_path(v0s, ssjgl_res)
```


#rags2ridges

```{r}
library(rags2ridges)
# define targe fused 
ns = c(n, n)
tlist <- default.target.fused(data$Sigma, ns)

# Obtain regularized precision under optimal penalty
opt <- optPenalty.fused.auto(X, tlist, cv.method = "aLOOCV",
                            maxit.ridgeP.fused = 100)
# Use the optimal penalties
Plist <- ridgeP.fused(data$ , ns, lambda = opt$lambda, maxit = 100)

# Determine support regularized (standardized) precision under optimal penalty
res <- sparsify.fused(Plist, threshold = "top", verbose = FALSE)
round(res[[1]]$sparsePrecision, 1)
round(res[[2]]$sparsePrecision, 1)
```





